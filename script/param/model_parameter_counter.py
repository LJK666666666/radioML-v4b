"""
æ¨¡å‹å‚æ•°æ•°é‡ç»Ÿè®¡å·¥å…·
ç”¨äºè¯»å–ä¿å­˜çš„Kerasæ¨¡å‹æ–‡ä»¶å¹¶è¾“å‡ºå‚æ•°æ•°é‡ä¿¡æ¯
"""

import os
import sys
import tensorflow as tf
from tensorflow import keras
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(project_root)

# å¯¼å…¥è‡ªå®šä¹‰å±‚å’Œæ¿€æ´»å‡½æ•°
try:
    from src.model.complex_nn_model import (
        ComplexConv1D, ComplexBatchNormalization, ComplexDense, ComplexMagnitude, 
        ComplexActivation, ComplexPooling1D,
        complex_relu, mod_relu, zrelu, crelu, cardioid, complex_tanh, phase_amplitude_activation,
        complex_elu, complex_leaky_relu, complex_swish, real_imag_mixed_relu
    )
    from src.model.hybrid_complex_resnet_model import (
        ComplexResidualBlock, ComplexResidualBlockAdvanced, ComplexGlobalAveragePooling1D
    )
    from src.model.hybrid_transition_resnet_model import (
        ComplexResidualBlock as TransitionComplexResidualBlock,
        HybridTransitionBlock
    )
    print("âœ… æˆåŠŸå¯¼å…¥è‡ªå®šä¹‰å±‚")
except ImportError as e:
    print(f"âš ï¸  è­¦å‘Š: å¯¼å…¥è‡ªå®šä¹‰å±‚å¤±è´¥: {e}")
    print("æ¨¡å‹åŠ è½½å¯èƒ½ä¼šå¤±è´¥")

def count_model_parameters(model_path):
    """
    è¯»å–Kerasæ¨¡å‹æ–‡ä»¶å¹¶ç»Ÿè®¡å‚æ•°æ•°é‡
    
    Args:
        model_path (str): æ¨¡å‹æ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: åŒ…å«å‚æ•°ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    try:
        # åŠ è½½æ¨¡å‹
        model = keras.models.load_model(model_path)
        
        # ç»Ÿè®¡æ€»å‚æ•°æ•°é‡
        total_params = model.count_params()
        
        # ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°æ•°é‡
        trainable_params = sum([np.prod(var.shape) for var in model.trainable_variables])
        
        # ç»Ÿè®¡ä¸å¯è®­ç»ƒå‚æ•°æ•°é‡
        non_trainable_params = total_params - trainable_params
        
        # è·å–æ¨¡å‹ç»“æ„ä¿¡æ¯
        model_layers = len(model.layers)
        
        return {
            'model_path': model_path,
            'model_name': os.path.basename(model_path),
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'non_trainable_parameters': non_trainable_params,
            'total_layers': model_layers,
            'model_loaded': True,
            'error': None
        }
        
    except Exception as e:
        return {
            'model_path': model_path,
            'model_name': os.path.basename(model_path),
            'total_parameters': 0,
            'trainable_parameters': 0,
            'non_trainable_parameters': 0,
            'total_layers': 0,
            'model_loaded': False,
            'error': str(e)
        }

def format_number(num):
    """æ ¼å¼åŒ–æ•°å­—ï¼Œæ·»åŠ åƒä½åˆ†éš”ç¬¦"""
    return f"{num:,}"

def print_model_info(model_info):
    """
    æ‰“å°æ¨¡å‹å‚æ•°ä¿¡æ¯
    
    Args:
        model_info (dict): æ¨¡å‹ä¿¡æ¯å­—å…¸
    """
    print(f"\n{'='*60}")
    print(f"æ¨¡å‹åç§°: {model_info['model_name']}")
    print(f"æ¨¡å‹è·¯å¾„: {model_info['model_path']}")
    print(f"{'='*60}")
    
    if model_info['model_loaded']:
        print(f"æ€»å‚æ•°æ•°é‡:     {format_number(model_info['total_parameters'])}")
        print(f"å¯è®­ç»ƒå‚æ•°:     {format_number(model_info['trainable_parameters'])}")
        print(f"ä¸å¯è®­ç»ƒå‚æ•°:   {format_number(model_info['non_trainable_parameters'])}")
        print(f"ç½‘ç»œå±‚æ•°:       {model_info['total_layers']}")
        
        # è®¡ç®—å‚æ•°å¤§å°ï¼ˆå‡è®¾float32ï¼Œæ¯ä¸ªå‚æ•°4å­—èŠ‚ï¼‰
        param_size_mb = (model_info['total_parameters'] * 4) / (1024 * 1024)
        print(f"ä¼°è®¡æ¨¡å‹å¤§å°:   {param_size_mb:.2f} MB")
    else:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {model_info['error']}")

def analyze_all_models():
    """åˆ†ææ‰€æœ‰ä¿å­˜çš„æ¨¡å‹"""
    model_dir = os.path.join(project_root, 'model_weight_saved')
    
    if not os.path.exists(model_dir):
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
        return
    
    # è·å–æ‰€æœ‰.kerasæ–‡ä»¶
    model_files = [f for f in os.listdir(model_dir) if f.endswith('.keras')]
    
    if not model_files:
        print(f"âŒ åœ¨ {model_dir} ä¸­æœªæ‰¾åˆ°.kerasæ¨¡å‹æ–‡ä»¶")
        return
    
    print(f"å‘ç° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")
    
    all_model_info = []
    
    for model_file in sorted(model_files):
        model_path = os.path.join(model_dir, model_file)
        model_info = count_model_parameters(model_path)
        all_model_info.append(model_info)
        print_model_info(model_info)
    
    # æ‰“å°æ±‡æ€»ä¿¡æ¯
    print_summary(all_model_info)

def print_summary(all_model_info):
    """æ‰“å°æ‰€æœ‰æ¨¡å‹çš„æ±‡æ€»ä¿¡æ¯"""
    print(f"\n{'='*80}")
    print("æ¨¡å‹å‚æ•°æ±‡æ€»è¡¨")
    print(f"{'='*80}")
    print(f"{'æ¨¡å‹åç§°':<40} {'æ€»å‚æ•°':<15} {'å¯è®­ç»ƒå‚æ•°':<15} {'çŠ¶æ€':<10}")
    print(f"{'-'*80}")
    
    for info in all_model_info:
        status = "âœ… æˆåŠŸ" if info['model_loaded'] else "âŒ å¤±è´¥"
        model_name = info['model_name'][:37] + "..." if len(info['model_name']) > 40 else info['model_name']
        
        print(f"{model_name:<40} {format_number(info['total_parameters']):<15} "
              f"{format_number(info['trainable_parameters']):<15} {status:<10}")

def analyze_specific_model(model_name):
    """åˆ†æç‰¹å®šæ¨¡å‹"""
    model_path = os.path.join(project_root, 'model_weight_saved', model_name)
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    model_info = count_model_parameters(model_path)
    print_model_info(model_info)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Kerasæ¨¡å‹å‚æ•°ç»Ÿè®¡å·¥å…·")
    print("=" * 60)
    
    if len(sys.argv) > 1:
        # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œåˆ†æç‰¹å®šæ¨¡å‹
        model_name = sys.argv[1]
        if not model_name.endswith('.keras'):
            model_name += '.keras'
        analyze_specific_model(model_name)
    else:
        # å¦åˆ™åˆ†ææ‰€æœ‰æ¨¡å‹
        analyze_all_models()

if __name__ == "__main__":
    main()
